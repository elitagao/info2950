{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8038aff",
   "metadata": {},
   "source": [
    "### Data Description: Ulta Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ba7499",
   "metadata": {},
   "source": [
    "**What are the observations (rows) and the attributes (columns)?**\n",
    "\n",
    "The obesrvations are the face moisturizer products listed on the [Ulta](https://www.ulta.com/skin-care-face-moisturizer?N=27h9) website. The attributes are the product's brand, name, price($), rating, and a list of ingredients.\n",
    "\n",
    "**Why was this dataset created?** \n",
    "\n",
    "This data set was created to accompany the Sephora dataset we have. The dataset includes more products to see if there are relationships present between product ingredients, ratings, and price that were overrepresented or underrepresented by only looking at the Sephora website data. \n",
    "\n",
    "**Who funded the creation of the dataset?** \n",
    "\n",
    "No one funded the creation of this dataset. Our group webscraped public data on Ulta's website to get build this dataset. \n",
    "\n",
    "**What processes might have influenced what data was observed and recorded and what was not?**\n",
    "\n",
    "Due to the complicated nature of webscrapping Ulta's website, it was not feasible to get all skin care products in a timely manner. Therefore, we decided to focus on just the face moisturizer category of products. We used Selenium WebDriver to webscrape. In this process we had to extract specific xpaths to get all of the attribute of a product. We then looped over every face moisturizer to get all the information for each product. Some product's attributes were not at the same xpath as the first product we used, so some data was not recorded. To remedy this, we manually filled in the missing data that was not successfully webscraped.  \n",
    "\n",
    "**What preprocessing was done, and how did the data come to be in the form that you are using?** \n",
    "\n",
    "As briefly mentioned above, we used Selenium WebDriver to webscrape Ulta's face moisterizer website page. We looped through each face moisterizer product to extract its attributes and stored it in a CSV file. We had 7 CSV files (one for each page of products) that we combined into one larger CSV file. Then, we manually filled in the missing data that was not successfully webscraped. Finally, we imported the CSV file into our notebook and saved it as a dataframe to use for our analyses. \n",
    "\n",
    "**If people are involved, were they aware of the data collection and if so, what purpose did they expect the data to be used for?**\n",
    "\n",
    "No people were involved.\n",
    "\n",
    "**Where can your raw source data be found, if applicable? Provide a link to the raw data (hosted in a Cornell Google Drive or Cornell Box).**\n",
    "\n",
    "Our raw data can be found in our group's Github [here](https://github.com/elitagao/info2950/blob/cf5f7ce3ec1d5999368a05c196c3aeba93ec28ac/combined_ulta.csv)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
